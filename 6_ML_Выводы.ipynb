{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Задачи\n",
    "1. Предскажем как просто направленности свечи, так и ее величину. В каких-то ситуациях важен тренд, а не конкретное изменение, поэтому предсказания в виде 0 или 1 тоже будет полезно и скорее всего более точным, нежели точное изменение \n",
    "2. Обучение будем проводить на основании линейной регрессии, линейной классификации и логистической регресии."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Машинное обучение"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Разделим данные на признаки и целевую переменную"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Нужные пакеты\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.linear_model import LinearRegression, Lasso, LogisticRegression\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score, mean_absolute_percentage_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_lr = X.drop(columns=['target', 'target_trend'])\n",
    "y = X['target']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для начала закодируем катеориальные признаки, используя OHE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_features = [col for col in X.columns if 'weekday' in col or 'colour' in col]\n",
    "\n",
    "X_lr = X.drop(columns=['target', 'target_trend'])\n",
    "y = X['target']\n",
    "\n",
    "X_lr = pd.get_dummies(X_lr, columns=categorical_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проведём теперь предобработку данных для машинного обучения, разделим выборку на тренировочную и тестовую, затем проведём нормализацию данных для того, чтобы признаки по равному влияли на вывод модели.\n",
    "Мы решили использовать именно MinMaxScaler, потому что он сохраняет распределение данных, а только переводит данные в заданный диапазон."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_lr, y, test_size=0.2, random_state=42)\n",
    "scaler = MinMaxScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Перейдём теперь к самому интересному - машинному обучению, для начала обучим обычную модель линейной регрессии и оценим её результаты."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LinearRegression()\n",
    "lr.fit(X_train_scaled, y_train)\n",
    "\n",
    "y_pred_train=lr.predict(X_train_scaled)\n",
    "y_pred = lr.predict(X_test_scaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обучив, обычную линейную модель мы решили использовать,метрики качества такие как MAE,MSE и R2. \\\n",
    "MAE и MSE - дают представление о точности предсказаний модели, но с разным акцентом. MAE показывает среднюю ошибку, а MSE выделяет крупные ошибки, что позволяет получить более полное представление о поведении модели. \\\n",
    "R²-коэффициент детерминации показывает, насколько хорошо модель объясняет дисперсию целевой переменной, что полезно для общей оценки качества модели. \\\n",
    "MAPE мы решили не использовать, поскольку иногда у нас бывает, что целевая перменная равно 0 и из-за этого MAPE мог бы получаться слишком огромным и нерепрезентативным."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error (MSE): 2.398452151717339e-07\n",
      "Mean Absolute Error (MAE): 0.0002779115913597876\n",
      "R2 0.7342666925858948\n"
     ]
    }
   ],
   "source": [
    "mse = mean_squared_error(y_train, y_pred_train)\n",
    "mae = mean_absolute_error(y_train, y_pred_train)\n",
    "r2 = r2_score(y_train, y_pred_train)\n",
    "mape=mean_absolute_percentage_error(y_train,y_pred_train)\n",
    "\n",
    "print(\"Mean Squared Error (MSE):\", mse)\n",
    "print(\"Mean Absolute Error (MAE):\", mae)\n",
    "print(\"R2\",r2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "На тренировочных данных достаточно хорошие получились результаты, однако гораздо важнее проверить модель на тестовых данных."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error (MSE): 2.5933575040877824e-07\n",
      "Mean Absolute Error (MAE): 0.00028181756538998317\n",
      "R2 0.7303753643522173\n"
     ]
    }
   ],
   "source": [
    "mse = mean_squared_error(y_test, y_pred)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "mape=mean_absolute_percentage_error(y_test,y_pred)\n",
    "\n",
    "print(\"Mean Squared Error (MSE):\", mse)\n",
    "print(\"Mean Absolute Error (MAE):\", mae)\n",
    "print(\"R2\",r2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Маленькие значения MSE и MAE указывают на высокую точность модели, однако стоит понимать, что MSE такой низкий не из-за того, что модель предсказывает небольшие величины и если возвести дробь в квадрат, то дробь станет ещё меньше. \\\n",
    "Высокое значение R² (0.73) указывает на то, что модель объясняет значительную часть вариации в данных. В контексте предсказания изменений стоимости акций, где данные могут быть очень шумными и сложными для предсказания, это хороший результат."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Попробуем теперь провести регуляризацию L1 с использованием Лассо. Лассо полезен особенно для нашей модели, у нас поскольку множество признаков,Лассо поможет отобрать признаки, уменьшая некоторые коэффициенты до нуля. Лассо добавляет штраф за абсолютное значение коэффициентов, что приводит к тому, что незначимые признаки могут быть исключены из модели. Это помогает улучшить обобщающую способность модели и уменьшить переобучение."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error (MSE): 2.81693546112782e-07\n",
      "Mean Absolute Error (MAE): 0.0002873343370107747\n",
      "R2: 0.7071305455754864\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LassoCV\n",
    "lasso_cv = LassoCV(cv=5, random_state=42)\n",
    "lasso_cv.fit(X_train_scaled, y_train)\n",
    "\n",
    "best_alpha = lasso_cv.alpha_\n",
    "\n",
    "lasso = Lasso(alpha=best_alpha)\n",
    "lasso.fit(X_train_scaled, y_train)\n",
    "\n",
    "y_pred = lasso.predict(X_test_scaled)\n",
    "\n",
    "mse_lasso_cv = mean_squared_error(y_test, y_pred)\n",
    "mae_lasso_cv = mean_absolute_error(y_test, y_pred)\n",
    "r2_lasso_cv = r2_score(y_test, y_pred)\n",
    "mape_lasso_cv = mean_absolute_percentage_error(y_test, y_pred)\n",
    "print(\"Mean Squared Error (MSE):\", mse_lasso_cv)\n",
    "print(\"Mean Absolute Error (MAE):\", mae_lasso_cv)\n",
    "print(\"R2:\", r2_lasso_cv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Качество модели слегка упало, видимо из-за специфики, Лассо регуляризации некоторые коэффициент стали равны 0, из-за чего модель потеряли некоторые важные взаимосвязи модели и качество ухудшилосью\n",
    "\n",
    "Интересно построить модель на схожести свечей с другими, поскольку явно то, что было в прошлом могло повториться в будущем и быть может это поможет нам делать более точные прогнозы. Возможно,другой метод машинного обучения KNN будет эффективно использовать исторические данные для предсказания будущих значений, основываясь на схожести текущих условий с прошлыми."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal value of k: 9\n",
      "KNN Regression:\n",
      "Mean Squared Error (MSE): 5.671720326635939e-07\n",
      "Mean Absolute Error (MAE): 0.00044100121355314435\n",
      "R-squared (R²): 0.4103259870053092\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "k_range = range(1, 10)\n",
    "k_scores = []\n",
    "\n",
    "for k in k_range:\n",
    "    knn = KNeighborsRegressor(n_neighbors=k)\n",
    "    scores = cross_val_score(knn, X_train_scaled, y_train, cv=5, scoring='neg_mean_squared_error')\n",
    "    k_scores.append(scores.mean())\n",
    "\n",
    "optimal_k = k_range[np.argmax(k_scores)]\n",
    "print(f\"Optimal value of k: {optimal_k}\")\n",
    "\n",
    "knn = KNeighborsRegressor(n_neighbors=optimal_k)\n",
    "knn.fit(X_train_scaled, y_train)\n",
    "\n",
    "y_pred = knn.predict(X_test_scaled)\n",
    "\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "mape = mean_absolute_percentage_error(y_test, y_pred)\n",
    "\n",
    "print(\"KNN Regression:\")\n",
    "print(\"Mean Squared Error (MSE):\", mse)\n",
    "print(\"Mean Absolute Error (MAE):\", mae)\n",
    "print(\"R-squared (R²):\", r2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LogReg для CRS\n",
    "CRS - Change0, Rsi0, Slowk0\n",
    "\n",
    "Некторые пункты в объяснении будут пропущены, так как трактовка схожих строк кода была выше\n",
    "\n",
    "Теперь оценим не точное измение свечи, а ее направление. Предсказывать будем через логистическую регрессию. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mse= 0.29977341389728096\n",
      "Precision: 0.72829674271775\n",
      "Recall: 0.70976087260523\n"
     ]
    }
   ],
   "source": [
    "X_CRS = X[['change0', 'rsi0', 'slowk0']]\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "X_CRS_scaled = scaler.fit_transform(X_CRS)\n",
    "y_CRS = X['target_trend']\n",
    "\n",
    "LogReg = LogisticRegression()\n",
    "X_train, X_test,  y_train, y_test = train_test_split(X_CRS_scaled, y_CRS, test_size=0.2, random_state=34)\n",
    "LogReg.fit(X_train, y_train)\n",
    "y_predict = LogReg.predict(X_test)\n",
    "\n",
    "mse = mean_squared_error(y_predict, y_test)\n",
    "precision = precision_score(y_predict, y_test)\n",
    "recall = recall_score(y_predict, y_test)\n",
    "\n",
    "print('mse=', mse)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Предсказания с ограниченным количеством параметров, которые были выбраны, исходя из графиков и интерпретаций выше, достаточно хороши, но нужно проверить предсказания и со всей имеющейся информацией\n",
    "\n",
    "# LogReg для all\n",
    "all - all columns execpt of ['target', 'target_trend']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mse= 0.16975075528700906\n",
      "Precision: 0.8439517864829962\n",
      "Recall: 0.8352623730739189\n"
     ]
    }
   ],
   "source": [
    "\n",
    "categorical_features = [col for col in X.columns if 'weekday' in col or 'colour' in col]\n",
    "\n",
    "X_all = X.drop(columns=['target', 'target_trend'])\n",
    "y = X['target']\n",
    "\n",
    "X_all = pd.get_dummies(X_all, columns=categorical_features)\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "X_all_scaled = scaler.fit_transform(X_all)\n",
    "y_all = X['target_trend']\n",
    "\n",
    "LogReg = LogisticRegression()\n",
    "X_train, X_test,  y_train, y_test = train_test_split(X_all_scaled, y_all, test_size=0.2, random_state=34)\n",
    "LogReg.fit(X_train, y_train)\n",
    "y_predict = LogReg.predict(X_test)\n",
    "\n",
    "mse = mean_squared_error(y_predict, y_test)\n",
    "precision = precision_score(y_predict, y_test)\n",
    "recall = recall_score(y_predict, y_test)\n",
    "\n",
    "print('mse=', mse)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как мы видим предсказания на модели с большим количеством параметров происходят лучше, что вполне ожидаемо."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Вывод и заключение проекта\n",
    "\n",
    "По ходу проекта мы спарсили котировки с MOEX. После мы расширили данные новыми колонками. Полученные дата фреймы были предварительно обработали, тажке мы применили созданные функции для агрегации новых показателей по типы \"change_all\". \n",
    "\n",
    "Новые колонки со свечными паттернами в датафрейми объснили в отдельном файле.\n",
    "\n",
    "Также на основе анализа графиков котировок и иных спомогательных графиков были выведены уже итогвые графики, которые в последствии были интепретированы. \n",
    "\n",
    "После анализа данных в разных его проявлениях были выдвинуты гипотезы, которые статистически проверены или опровергнуты. \n",
    "\n",
    "Под конец проекта были поставлены задачи на ML, и, основываясь на них, было проведено несколько типов машинного обучения в зависимости от требуемых задач и введенных предпосылок\n",
    "\n",
    "Итоги каждого из подэтапов последовательно выписывались с прилагающейся интепретацией. Отдельно хочет отметить реалистичный результат каждого из видов машинного обучения, которые описаны выше"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
